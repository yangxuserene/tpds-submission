\section{Introduction}
\label{sec:intro}

Low-latency and high-bandwidth interconnect networks play a critical role in ensuring HPC system performance. 
The high-radix, low-diameter dragonfly topology can lower the overall cost of the interconnect, improve network bandwidth and reduce packet latency \cite{dally-dragonfly}, 
making it a very promising choice for building supercomputers with millions of cores.
Even with such powerful networks, 
intelligent job placement is of paramount importance to the efficient use of dragonfly connected systems~\cite{bhatele:ipdps2016, jain-sc14}.
%In order to explore the full potential of such powerful networks,  
%intelligent job placement is of paramount importance~\cite{bhatele2015, jain-sc14}. 

Recent studies suggest that random node allocation for parallel jobs, coupled
with adaptive routing, can alleviate local congestion, eliminate hot-spots and achieve load-balancing for dragonfly networks~\cite{jain-sc14, bhatele-sc11, brandt2014}. 
These studies explore the possible job placement and routing configurations that could optimize the overall network performance without examining how different configurations impact the progress of individual applications.
\emph{In this paper, we study the implications of contention for shared network links in the context of multiple HPC applications running on dragonfly systems when different job placement and routing configurations are in use.}
Our analyses focus on the overall network performance as well as the performance of concurrently executing applications in the presence of network contention.

%We have observed that when running concurrently on the dragonfly network, applications interfere with each other and the less communication-intensive applications are ``bullied" by the communication-intensive ones. The ``bully" applications get great performance improvement at the cost of performance degradation to the ``bullied" applications. We choose three representative applications from the DOE Design Forward Project~\cite{designforwardwebpage} to study the root cause of the ``bullying" with simulation on CODES, an high-fidelity, packet-level HPC network simulation toolkit~\cite{codes}. 


We choose three representative HPC applications from the DOE Design Forward Project~\cite{designforward-webpage} and analyze the interference among them. Our study is based on simulation with CODES, a high-fidelity, flit-level HPC network simulation toolkit~\cite{misbah-tpds}. 
For each application, we examine its performance with two job placement policies and three routing policies.
We make the following observations through extensive simulations.


%In this work, we study the interference between concurrently running jobs on dragonfly networks with different job placement and routing policies. We use CODES, an HPC network simulation toolkit with high fidelity and excellent scalability for packet level simulation \cite{codes}. Unlike much existing work that rely on synthetic workloads, we use traces of three representative applications from the DOE Design Forward Project \cite{designforwardwebpage}. The advantage of using real application traces is straight forward: these traces can capture detailed application communication behaviors that are omitted in synthetic workload for simplification. Applications are usually distinctive from each other in data transfer amount, communication pattern, operation dependency etc., which can be impractical to reproduce in a synthetic workload.

%We conduct extensive experiments with three applications running on dragonfly network with two job placement policies and three routing policies. We analyze the performance of network as well as individual application when running with different placement and routing configurations. Our evaluation is based on more than 1000 runs of simulation. We make the following interesting observations through extensive simulation.


\begin{itemize}
   
    \item Concurrently running applications on a dragonfly network interfere with each other when they share network resources. Communication-intensive applications ``bully" their less intensive peers and obtain performance improvement at the expense of less intensive ones. 
    
    \item Random placement of application processes in the dragonfly can improve the performance of communication-intensive applications by enabling network resource sharing, though it introduces interference causing performance degradation to the less intensive applications.
    
   \item Contiguous placement can be beneficial to the consistent performance of less communication-intensive applications by minimizing network resource sharing, because it reduces the opportunities for traffic from other applications to be loaded on links that serve as minimal routes for the less intensive application. However, this comes with the downside of reduced system performance due to load imbalance.
    
%    \item Random router and random partition placement benefit the less communication intensive applications by grouping a subset of nodes together (preserving locality) to reduce network sharing. However, preserving locality introduces performance degradation to intensive applications due to local congestion.    
        
\end{itemize}

Based on the aforementioned key observations, one would expect that an ideal job placement policy on dragonfly systems would take relative communication intensity into account, and mix contiguous and non-contiguous placement based on application needs. To explore this expectation, we investigate \emph{a hybrid job placement policy}, which assigns random allocations to communication-intensive applications and contiguous allocations to less intensive ones. Initial experimentation shows that hybrid job placement aids in reducing the worst-case performance degradation for less communication-intensive applications while retaining the performance of communication-intensive applications, though without eliminating the problem entirely. Further more, we explore two possible placement policies, random router and random partition, that have been discussed in the community. Based on the experimental results, random router and random partition placement bring great performance improvement for the less intensive application at the cost of performance degradation for intensive ones. Unfortunately, none of them can completely prevent the ``bully" behavior from happening. 

To the best of our knowledge, using real application traces from production systems for the study of job interference on dragonfly networks has not been reported in the literature so far. We believe the observations and new placement policy presented in this paper are valuable to the HPC community.
We believe the observations and new placement policy presented in this paper are valuable to a number of communities including HPC computing facilcities, system software developers, and system administrators and HPC users. 
The computing facilities should take network resource sharing into consideration when choosing proper configurations for building their dragonfly networks. System software developers could design better scheduling algorithms for jobs with distinct communication behavior. System administrators could make more accurate predication about system availability based on job running status under different placement and routing configurations. Users can provide detail information about their applications such that batch scheduler could provide the optimal allocation to guarantee the quality of service. 


The rest of this paper is organized as follows. Section~\ref{sec:background} describes an implementation of the dragonfly network, introduces the placement policies and routing policies. Section~\ref{sec: methodology} discusses the use of CODES as a research vehicle and three representative applications from the DOE Design Forward Project. Section~\ref{sec:workload-1} presents the observations and analysis of three applications running on a dragonfly network with different placement and routing configurations. Section~\ref{sec:workload-2} validates the observations we obtain from previous section. Section~\ref{sec: hybrid placement} presents a alternative placement policy for the dragonfly network. Section~\ref{sec: other_placement_policies} explores two other possible job placement policies that have been discussed in previous literature. 
Section~\ref{sec:related work} discusses the related work. Finally, the conclusion is presented in Section~\ref{sec:conclusion}.


